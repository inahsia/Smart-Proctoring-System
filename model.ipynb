{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076600f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proctoring started. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "# === Setup for Anti-Cheating Proctoring System (Late Fusion) ===\n",
    "# Models: MediaPipe (Face + Gaze), YOLOv8 (Object Detection), ArcFace (Face ID)\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------\n",
    "# Load Models\n",
    "# ------------------------\n",
    "\n",
    "# 1. MediaPipe Face Mesh + Iris for gaze\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# 2. YOLOv8 for object detection (detect phones)\n",
    "yolo_model = YOLO(\"yolov8n.pt\")  # Or your custom-trained cheating detector\n",
    "\n",
    "# 3. ArcFace/FaceNet for face identity verification (stubbed here)\n",
    "def verify_identity(face_crop):\n",
    "    # Placeholder: should compare embeddings to enrolled ID\n",
    "    return True\n",
    "\n",
    "# ------------------------\n",
    "# Process Frame\n",
    "# ------------------------\n",
    "def analyze_frame(frame):\n",
    "    results = {}\n",
    "\n",
    "    # ---------- Face Detection ----------\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_detection.process(rgb)\n",
    "\n",
    "    results['face_present'] = bool(face_result.detections)\n",
    "\n",
    "    # ---------- Gaze Estimation ----------\n",
    "    gaze_off_screen = False\n",
    "    if face_result.detections:\n",
    "        mesh_result = face_mesh.process(rgb)\n",
    "        if mesh_result.multi_face_landmarks:\n",
    "            for landmarks in mesh_result.multi_face_landmarks:\n",
    "                left_eye = np.array([\n",
    "                    landmarks.landmark[474].x,\n",
    "                    landmarks.landmark[474].y\n",
    "                ])\n",
    "                if left_eye[0] < 0.3 or left_eye[0] > 0.7:\n",
    "                    gaze_off_screen = True\n",
    "\n",
    "    results['gaze_off_screen'] = gaze_off_screen\n",
    "\n",
    "    # ---------- Object Detection (Phone) ----------\n",
    "    detections = yolo_model(frame, verbose=False)[0]\n",
    "    phone_detected = False\n",
    "    for det in detections.boxes:\n",
    "        cls = int(det.cls[0])\n",
    "        if yolo_model.names[cls].lower() in [\"cell phone\", \"phone\"]:\n",
    "            phone_detected = True\n",
    "            break\n",
    "    results['phone_detected'] = phone_detected\n",
    "    \n",
    "    \n",
    "\n",
    "    # ---------- Identity Check ----------\n",
    "    results['identity_verified'] = verify_identity(frame)  # Stub\n",
    "\n",
    "    return results\n",
    "\n",
    "# ------------------------\n",
    "# Run Live Webcam Check\n",
    "# ------------------------\n",
    "def run_proctoring():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Proctoring started. Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = analyze_frame(frame)\n",
    "\n",
    "        status = \"âœ… Normal\"\n",
    "        color = (0, 255, 0)\n",
    "        if not results['face_present'] or not results['identity_verified'] or results['phone_detected'] or results['gaze_off_screen']:\n",
    "            status = \"ðŸš¨ Cheating Detected\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        cv2.putText(frame, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        cv2.imshow(\"Proctoring\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ------------------------\n",
    "# Run System\n",
    "# ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_proctoring()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7e56c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proctoring started. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "# === Setup for Anti-Cheating Proctoring System (Late Fusion with Weights) ===\n",
    "# Models: MediaPipe (Face + Gaze), YOLOv8 (Object Detection), ArcFace (Face ID)\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------\n",
    "# Load Models\n",
    "# ------------------------\n",
    "\n",
    "# 1. MediaPipe Face Mesh + Iris for gaze\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# 2. YOLOv8 for object detection (detect phones)\n",
    "yolo_model = YOLO(\"yolov8n.pt\")  # Or your custom-trained cheating detector\n",
    "\n",
    "# 3. ArcFace/FaceNet for face identity verification (stubbed here)\n",
    "def verify_identity(face_crop):\n",
    "    # Placeholder: should compare embeddings to enrolled ID\n",
    "    return True\n",
    "\n",
    "# ------------------------\n",
    "# Process Frame\n",
    "# ------------------------\n",
    "def analyze_frame(frame):\n",
    "    results = {}\n",
    "\n",
    "    # ---------- Face Detection ----------\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_result = face_detection.process(rgb)\n",
    "\n",
    "    results['face_present'] = bool(face_result.detections)\n",
    "\n",
    "    # ---------- Gaze Estimation ----------\n",
    "    gaze_off_screen = False\n",
    "    if face_result.detections:\n",
    "        mesh_result = face_mesh.process(rgb)\n",
    "        if mesh_result.multi_face_landmarks:\n",
    "            for landmarks in mesh_result.multi_face_landmarks:\n",
    "                left_eye = np.array([\n",
    "                    landmarks.landmark[474].x,\n",
    "                    landmarks.landmark[474].y\n",
    "                ])\n",
    "                if left_eye[0] < 0.3 or left_eye[0] > 0.7:\n",
    "                    gaze_off_screen = True\n",
    "\n",
    "    results['gaze_off_screen'] = gaze_off_screen\n",
    "\n",
    "    # ---------- Object Detection (Phone) ----------\n",
    "    detections = yolo_model(frame, verbose=False)[0]\n",
    "    phone_detected = False\n",
    "    for det in detections.boxes:\n",
    "        cls = int(det.cls[0])\n",
    "        if yolo_model.names[cls].lower() in [\"cell phone\", \"phone\"]:\n",
    "            phone_detected = True\n",
    "            break\n",
    "    results['phone_detected'] = phone_detected\n",
    "\n",
    "    # ---------- Identity Check ----------\n",
    "    results['identity_verified'] = verify_identity(frame)  # Stub\n",
    "\n",
    "    return results\n",
    "\n",
    "# ------------------------\n",
    "# Run Live Webcam Check\n",
    "# ------------------------\n",
    "def run_proctoring():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Proctoring started. Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = analyze_frame(frame)\n",
    "\n",
    "        # ------------------------\n",
    "        # Weighted Score Calculation\n",
    "        # ------------------------\n",
    "\n",
    "        # Assign weights\n",
    "        w_face_absence = 0.25\n",
    "        w_identity_mismatch = 0.25\n",
    "        w_phone_detected = 0.3\n",
    "        w_gaze_off_screen = 0.2\n",
    "\n",
    "        # Boolean -> 0 or 1\n",
    "        face_score = int(not results['face_present'])\n",
    "        identity_score = int(not results['identity_verified'])\n",
    "        phone_score = int(results['phone_detected'])\n",
    "        gaze_score = int(results['gaze_off_screen'])\n",
    "\n",
    "        # Weighted cheating score\n",
    "        cheating_score = (\n",
    "            w_face_absence * face_score +\n",
    "            w_identity_mismatch * identity_score +\n",
    "            w_phone_detected * phone_score +\n",
    "            w_gaze_off_screen * gaze_score\n",
    "        )\n",
    "\n",
    "        CHEATING_THRESHOLD = 0.3  # Tune as needed\n",
    "\n",
    "        if cheating_score > CHEATING_THRESHOLD:\n",
    "            status = f\"ðŸš¨ Cheating ({cheating_score:.2f})\"\n",
    "            color = (0, 0, 255)\n",
    "        else:\n",
    "            status = f\"âœ… Normal ({cheating_score:.2f})\"\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "        cv2.putText(frame, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        cv2.imshow(\"Proctoring\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ------------------------\n",
    "# Run System\n",
    "# ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_proctoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4caf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
